{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ee00e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3p/8hc9c44s38j902ytq253kt6m0000gn/T/ipykernel_3096/3789481576.py:4: DtypeWarning: Columns (339) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../데이터/VIP_churnscoreO_11460_826.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('../데이터/VIP_churnscoreO_11460_826.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fa15f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "군집별 데이터 개수:\n",
      "cluster_label\n",
      "0    3588\n",
      "1    6630\n",
      "2    1242\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df[['Churn_Score']]\n",
    "\n",
    "# KMeans 모델 생성 (군집 3개)\n",
    "# random_state를 고정하면 돌릴 때마다 똑같은 결과가 나와서 좋아.\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# 학습 및 예측 (군집 번호 0, 1, 2 생성)\n",
    "df['cluster_label'] = kmeans.fit_predict(X)\n",
    "\n",
    "# 각 군집별로 데이터가 몇 개씩 들어갔는지 확인해볼까?\n",
    "print(\"\\n군집별 데이터 개수:\")\n",
    "print(df['cluster_label'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5307afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "생성된 Target 변수 분포:\n",
      "Target\n",
      "0    7872\n",
      "1    3588\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn_Score</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn_Score  cluster_label  Target\n",
       "0          4.2              1       0\n",
       "1         13.5              0       1\n",
       "2         11.4              0       1\n",
       "3          7.2              1       0\n",
       "4          2.1              1       0\n",
       "5          2.6              1       0\n",
       "6          7.7              1       0\n",
       "7          8.9              0       1\n",
       "8          4.7              1       0\n",
       "9         13.8              0       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target 변수 생성 함수 정의\n",
    "def create_target(label):\n",
    "    if label == 0:\n",
    "        return 1  # 이탈 (군집 0)\n",
    "    else:\n",
    "        return 0  # 잔존 (군집 1, 2)\n",
    "\n",
    "# apply 함수를 써서 Target 컬럼 만들기\n",
    "df['Target'] = df['cluster_label'].apply(create_target)\n",
    "\n",
    "# 잘 만들어졌는지 결과 확인!\n",
    "print(\"\\n생성된 Target 변수 분포:\")\n",
    "print(df['Target'].value_counts())\n",
    "\n",
    "# 최종 데이터 확인\n",
    "display(df[['Churn_Score', 'cluster_label', 'Target']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c422b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [16:46:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1764148644238/work/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 모델 학습 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m X_vif = X.fillna(X.mean())\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# 모든 컬럼의 VIF 계산\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m vif_list = [\u001b[43mvariance_inflation_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_vif\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_vif.columns))]\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# --- [5. 데이터프레임 통합 및 정렬] ---\u001b[39;00m\n\u001b[32m     44\u001b[39m result_df = pd.DataFrame({\n\u001b[32m     45\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m'\u001b[39m: X.columns,\n\u001b[32m     46\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshap_importance\u001b[39m\u001b[33m'\u001b[39m: shap_importance,\n\u001b[32m     47\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mvif\u001b[39m\u001b[33m'\u001b[39m: vif_list\n\u001b[32m     48\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/statsmodels/stats/outliers_influence.py:196\u001b[39m, in \u001b[36mvariance_inflation_factor\u001b[39m\u001b[34m(exog, exog_idx)\u001b[39m\n\u001b[32m    194\u001b[39m mask = np.arange(k_vars) != exog_idx\n\u001b[32m    195\u001b[39m x_noti = exog[:, mask]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m r_squared_i = \u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_noti\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.rsquared\n\u001b[32m    197\u001b[39m vif = \u001b[32m1.\u001b[39m / (\u001b[32m1.\u001b[39m - r_squared_i)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vif\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:333\u001b[39m, in \u001b[36mRegressionModel.fit\u001b[39m\u001b[34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpinv\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    330\u001b[39m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnormalized_cov_params\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    331\u001b[39m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m         \u001b[38;5;28mself\u001b[39m.pinv_wexog, singular_values = \u001b[43mpinv_extended\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m         \u001b[38;5;28mself\u001b[39m.normalized_cov_params = np.dot(\n\u001b[32m    335\u001b[39m             \u001b[38;5;28mself\u001b[39m.pinv_wexog, np.transpose(\u001b[38;5;28mself\u001b[39m.pinv_wexog))\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# Cache these singular values for use later.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/statsmodels/tools/tools.py:264\u001b[39m, in \u001b[36mpinv_extended\u001b[39m\u001b[34m(x, rcond)\u001b[39m\n\u001b[32m    262\u001b[39m x = np.asarray(x)\n\u001b[32m    263\u001b[39m x = x.conjugate()\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m u, s, vt = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m s_orig = np.copy(s)\n\u001b[32m    266\u001b[39m m = u.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/numpy/linalg/_linalg.py:1862\u001b[39m, in \u001b[36msvd\u001b[39m\u001b[34m(a, full_matrices, compute_uv, hermitian)\u001b[39m\n\u001b[32m   1858\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->DdD\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->ddd\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1859\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_svd_nonconvergence,\n\u001b[32m   1860\u001b[39m               invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m, over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1861\u001b[39m               under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1862\u001b[39m     u, s, vh = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1863\u001b[39m u = u.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1864\u001b[39m s = s.astype(_realType(result_t), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# --- [1. 데이터 준비] ---\n",
    "# 분석에 불필요한 컬럼 제거 (ID, 날짜, 타겟, 군집 등)\n",
    "cols_to_drop = ['발급회원번호', '기준년월', 'Target', 'cluster_label', 'Churn_Score']\n",
    "# 실제 데이터프레임에 있는 컬럼만 골라서 드롭 (에러 방지)\n",
    "drop_cols = [c for c in cols_to_drop if c in sampled_df.columns]\n",
    "\n",
    "X = sampled_df.drop(columns=drop_cols)\n",
    "X = X.select_dtypes(include=[np.number]) # 숫자형 데이터만 선택\n",
    "y = sampled_df['Target']\n",
    "\n",
    "# --- [2. XGBoost 모델 학습] ---\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "model.fit(X, y)\n",
    "print(\"XGBoost 모델 학습 완료!\")\n",
    "\n",
    "# --- [3. SHAP 중요도(Mean |SHAP|) 계산] ---\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# 각 변수별 평균 절대값(Mean Absolute SHAP) 계산 -> 변수 중요도\n",
    "shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# --- [4. VIF 지수 계산] ---\n",
    "# 결측치는 평균으로 채워서 계산 (VIF 오류 방지)\n",
    "X_vif = X.fillna(X.mean())\n",
    "\n",
    "# 모든 컬럼의 VIF 계산\n",
    "vif_list = [variance_inflation_factor(X_vif.values, i) for i in range(len(X_vif.columns))]\n",
    "\n",
    "# --- [5. 데이터프레임 통합 및 정렬] ---\n",
    "result_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'shap_importance': shap_importance,\n",
    "    'vif': vif_list\n",
    "})\n",
    "\n",
    "# SHAP 중요도 기준으로 내림차순 정렬\n",
    "result_df = result_df.sort_values(by='shap_importance', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
