{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 시트 컬럼 추출 및 병합 (SHAP 기반 + 폴더 순회)\n",
                "\n",
                "이 노트북은 `VIP_shap_vif12.23.csv` 파일에서 SHAP 중요도가 0이 아닌 컬럼들을 추출하고,\n",
                "지정된 **폴더 내의 모든 CSV 파일**을 자동으로 탐색하여 해당 컬럼들의 데이터를 병합합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reading SHAP values from VIP_shap_vif12.23.csv...\n",
                        "Target columns loaded: 76 columns (SHAP != 0)\n",
                        "Top 5 targets: ['정상청구원금_B5M', 'CA이자율_할인전', '최종이용일자_기본', 'rv최초시작후경과일', '변동률_잔액_일시불_B1M', '이용금액_오프라인_R6M', '이용금액_쇼핑', '연체입금원금_B0M', '평잔_일시불_3M', '이용건수_신용_R12M', '이용금액_일시불_R6M', '이용금액_체크_R12M', '잔액_일시불_B2M', '월중평잔_일시불_B0M', '할부금액_무이자_3M_R12M', '최종유효년월_신용_이용가능', '잔액_신판평균한도소진율_r6m', '잔액_신판최대한도소진율_r6m', '쇼핑_편의점_이용금액', '이용건수_신용_R6M']\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "\n",
                "# 1. SHAP 파일 로드 및 타겟 컬럼 선정\n",
                "shap_csv_path = 'VIP_shap_vif12.23.csv'\n",
                "\n",
                "if os.path.exists(shap_csv_path):\n",
                "    print(f\"Reading SHAP values from {shap_csv_path}...\")\n",
                "    try:\n",
                "        shap_df = pd.read_csv(shap_csv_path)\n",
                "        \n",
                "        # SHAP importance가 0이 아닌 feature만 추출\n",
                "        target_columns = shap_df[shap_df['shap_importance'] != 0]['feature'].dropna().unique().tolist()\n",
                "        \n",
                "        print(f\"Target columns loaded: {len(target_columns)} columns (SHAP != 0)\")\n",
                "        print(\"Top 5 targets:\", target_columns[:20])\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error reading SHAP csv: {e}\")\n",
                "        target_columns = []\n",
                "else:\n",
                "    print(f\"Warning: {shap_csv_path} not found. Please check file path.\")\n",
                "    target_columns = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Scanning files in ../30만원본/...\n",
                        "Found 16 CSV files.\n",
                        " - 카드성과정보_300k.csv\n",
                        " - 카드승인정보_300k.csv\n",
                        " - 카드신용정보_300k.csv\n"
                    ]
                }
            ],
            "source": [
                "# 2. 대상 폴더 설정 및 파일 목록 자동 탐색\n",
                "# 분석할 CSV 파일들이 들어있는 폴더 경로를 입력하세요.\n",
                "target_folder = '../30만원본/' # <-- 여기에 경로 입력\n",
                "\n",
                "file_list = []\n",
                "\n",
                "if os.path.exists(target_folder):\n",
                "    print(f\"Scanning files in {target_folder}...\")\n",
                "    for root, dirs, files in os.walk(target_folder):\n",
                "        for file in files:\n",
                "            # 대소문자 구분 없이 csv 파일 찾기\n",
                "            if file.lower().endswith('.csv'):\n",
                "                full_path = os.path.join(root, file)\n",
                "                file_list.append(full_path)\n",
                "    \n",
                "    print(f\"Found {len(file_list)} CSV files.\")\n",
                "    # 확인을 위해 처음 3개만 출력\n",
                "    for f in file_list[:3]:\n",
                "        print(f\" - {os.path.basename(f)}\")\n",
                "else:\n",
                "    print(f\"Folder not found: {target_folder}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. 파일 순회 및 데이터 병합\n",
                "\n",
                "# 기준 키 컬럼\n",
                "key_cols = ['발급회원번호', '기준년월'] \n",
                "\n",
                "final_df = pd.DataFrame()\n",
                "found_log = []\n",
                "\n",
                "print(\"\\nStarting Merge Process...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for file_path in file_list:\n",
                "    try:\n",
                "        # 1) 헤더만 읽기 (encoding은 파일에 맞게 수정, 보통 cp949 or utf-8)\n",
                "        temp_header = pd.read_csv(file_path, nrows=0, encoding='cp949')\n",
                "        file_cols = list(temp_header.columns)\n",
                "        \n",
                "        # 2) 키 컬럼 확인\n",
                "        missing_keys = [k for k in key_cols if k not in file_cols]\n",
                "        if missing_keys:\n",
                "            print(f\"[SKIP] {os.path.basename(file_path)} -> Missing keys: {missing_keys}\")\n",
                "            continue\n",
                "            \n",
                "        # 3) 타겟 컬럼 확인\n",
                "        cols_to_read = [col for col in target_columns if col in file_cols]\n",
                "        \n",
                "        # 타겟 컬럼이 하나도 없으면 건너뜀\n",
                "        if not cols_to_read:\n",
                "            print(f\"[PASS] {os.path.basename(file_path)} -> No target columns found.\")\n",
                "            continue\n",
                "            \n",
                "        # 4) 데이터 로드 (키 + 타겟)\n",
                "        use_cols = list(set(key_cols + cols_to_read))\n",
                "        print(f\"[READ] {os.path.basename(file_path)} -> Found {len(cols_to_read)} target columns.\")\n",
                "        \n",
                "        current_df = pd.read_csv(file_path, usecols=use_cols, encoding='cp949')\n",
                "        \n",
                "        # 5) 병합 (Outer Join)\n",
                "        if final_df.empty:\n",
                "            final_df = current_df\n",
                "            print(f\"       -> Initialized final_df with shape {final_df.shape}\")\n",
                "        else:\n",
                "            before_shape = final_df.shape\n",
                "            # on=key_cols, how='outer'로 병합\n",
                "            final_df = pd.merge(final_df, current_df, on=key_cols, how='outer')\n",
                "            print(f\"       -> Merged. Shape: {before_shape} -> {final_df.shape}\")\n",
                "            \n",
                "        found_log.append(f\"{os.path.basename(file_path)}: {cols_to_read}\")\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f\"[ERROR] reading {file_path}: {e}\")\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"Merge Completed.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. 결과 확인 및 저장\n",
                "print(\"Final DataFrame Shape:\", final_df.shape)\n",
                "\n",
                "if not final_df.empty:\n",
                "    print(\"Columns:\", final_df.columns.tolist())\n",
                "    display(final_df.head())\n",
                "    \n",
                "# 필요시 저장\n",
                "# final_df.to_csv(\"merged_result_shap.csv\", index=False, encoding='utf-8-sig')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
