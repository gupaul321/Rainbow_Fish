{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21a2762b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3p/8hc9c44s38j902ytq253kt6m0000gn/T/ipykernel_4351/530037132.py:3: DtypeWarning: Columns (3323,3324,3325,3830,3831,3832,3833,3834,3835) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('VIP_ëª¨ë¸í•™ìŠµìš©_8902_4940.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('VIP_ëª¨ë¸í•™ìŠµìš©_8902_4940.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98507266",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_cols = [\n",
    "    'Score_BadDebt', 'Score_Delinq', 'Score_Activity', 'Score_Asset', \n",
    "    'Score_Status_Total', 'Slope_Spend', 'Slope_Balance', 'Slope_Count', \n",
    "    'Norm_Slope_Spend', 'Norm_Slope_Balance', 'Norm_Slope_Count', \n",
    "    'Score_Slope_Total', 'Final_Total_Score', 'Score_Clipped', \n",
    "    'Risk_Score_Centered', 'cluster_label', 'cluster_label_swapped', \n",
    "    'y_jitter', 'Target', 'ë°œê¸‰íšŒì›ë²ˆí˜¸' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30dd70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[col for col in exclude_cols if col in df.columns])\n",
    "y = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51efe5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. ë¬¸ìì—´(object) ì»¬ëŸ¼ë“¤ë§Œ ì™ì™ ì°¾ì•„ë‚´ê¸°\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 2. LabelEncoderë¡œ ìˆ«ìë¡œ ë°”ê¾¸ê¸°\n",
    "# ìƒë¦¼ì•„, ê²°ì¸¡ì¹˜(NaN)ê°€ ìˆìœ¼ë©´ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë‹ˆ ë¬¸ìì—´ \"None\"ìœ¼ë¡œ ì±„ìš°ê³  ì‹œì‘í• ê²Œ!\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in cat_cols:\n",
    "    # NaN ê°’ì„ 'Unknown'ì´ë¼ëŠ” ë¬¸ìë¡œ ì±„ì›Œì£¼ê³  ìˆ«ìë¡œ ë³€í™˜!\n",
    "    X[col] = X[col].fillna('Unknown').astype(str)\n",
    "    X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d3138b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒë¦¼ì•„! ì „ì²´ í”¼ì²˜ë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œëì–´! ğŸŒˆğŸŸ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë¹ˆì¹¸ 0ìœ¼ë¡œ ì±„ìš°ê¸° (SHAP/VIF ì—ëŸ¬ ë°©ì§€!)\n",
    "X = X.fillna(0)\n",
    "\n",
    "# 2. í•™ìŠµìš©(Train)ê³¼ í…ŒìŠ¤íŠ¸ìš©(Test) ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 3. ë°ì´í„° ë¶ˆê· í˜•ì„ ê³ ë ¤í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "# 4. XGBoost ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "model_full = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    scale_pos_weight=ratio, # ì´íƒˆìì—ê²Œ ìš©ê¸°ë¥¼ íŒ¡íŒ¡!\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "model_full.fit(X_train, y_train)\n",
    "\n",
    "print(\"ìƒë¦¼ì•„! ì „ì²´ í”¼ì²˜ë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œëì–´! ğŸŒˆğŸŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ae7ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒë¦¼ì•„! ì „ì²´ í”¼ì²˜ ëª¨ë¸ì˜ ì •í™•ë„ëŠ” 0.9444ì´ì•¼! ğŸŒˆ\n",
      "\n",
      "--- ğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ì„±ì í‘œ (Classification Report) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1491\n",
      "           1       0.86      0.79      0.82       290\n",
      "\n",
      "    accuracy                           0.94      1781\n",
      "   macro avg       0.91      0.88      0.89      1781\n",
      "weighted avg       0.94      0.94      0.94      1781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. í…ŒìŠ¤íŠ¸ ë°ì´í„°(X_test)ë¡œ ì˜ˆì¸¡í•˜ê¸°\n",
    "y_pred = model_full.predict(X_test)\n",
    "\n",
    "# 2. ì „ì²´ ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"ìƒë¦¼ì•„! ì „ì²´ í”¼ì²˜ ëª¨ë¸ì˜ ì •í™•ë„ëŠ” {accuracy:.4f}ì´ì•¼! ğŸŒˆ\")\n",
    "print(\"\\n--- ğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ì„±ì í‘œ (Classification Report) ---\")\n",
    "# '1' í–‰ì˜ recall(ì¬í˜„ìœ¨) ìˆ˜ì¹˜ê°€ ì´íƒˆìë¥¼ ì¡ì•„ë‚¸ ë¹„ìœ¨ì´ì•¼!\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # 3. í˜¼ë™ í–‰ë ¬(Confusion Matrix) ì‹œê°í™”\n",
    "# # ì‹¤ì œë¡œ ë§ì¶˜ ê²ƒê³¼ í‹€ë¦° ê²ƒì„ í•œëˆˆì— ë³´ì!\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eeee43f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒë¦¼ì•„! ìƒìœ„ 50ê°œ í•µì‹¬ í”¼ì²˜ì˜ VIF ì§€ìˆ˜ë¥¼ ê³„ì‚° ì¤‘ì´ì•¼. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ì¤˜! ğŸŒˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/myenv/lib/python3.13/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature  SHAP_Importance           VIF\n",
      "0   ì´ìš©ê±´ìˆ˜_ì¼ì‹œë¶ˆ_B0M_12         1.240356  1.098850e+05\n",
      "1    ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M_12         0.710747  2.762844e+05\n",
      "2    ì´ìš©ê±´ìˆ˜_ì‹ ìš©_R3M_12         0.628235  1.080745e+06\n",
      "3   ì´ìš©ê±´ìˆ˜_ì¼ì‹œë¶ˆ_R3M_12         0.524226  4.946697e+05\n",
      "4    ì´ìš©ê±´ìˆ˜_ì‹ ìš©_R3M_09         0.420482  1.174807e+06\n",
      "5   ì´ìš©ê±´ìˆ˜_ì¼ì‹œë¶ˆ_R3M_09         0.382424           inf\n",
      "6    ì´ìš©ê±´ìˆ˜_ì‹ íŒ_R3M_12         0.371672  1.546973e+06\n",
      "7    ì´ìš©ê±´ìˆ˜_ì‹ íŒ_B0M_07         0.353547  3.962352e+05\n",
      "8    ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M_07         0.338043  3.015606e+05\n",
      "9   ì´ìš©ê±´ìˆ˜_ì¼ì‹œë¶ˆ_B0M_11         0.328548  1.415565e+05\n",
      "10   ì´ìš©ê±´ìˆ˜_ì‹ íŒ_R3M_09         0.321982  1.609037e+06\n",
      "11   ì´ìš©ê±´ìˆ˜_ì‹ ìš©_B0M_11         0.265375  3.032559e+05\n",
      "12   ì´ìš©ê¸ˆì•¡_ì‹ íŒ_B0M_07         0.238251  4.741130e+02\n",
      "13  ì´ìš©ê±´ìˆ˜_ì¼ì‹œë¶ˆ_B0M_07         0.230263           inf\n",
      "14  ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_B0M_12         0.206168  2.214881e+02\n",
      "15   ì´ìš©ê±´ìˆ˜_ì‹ íŒ_B0M_12         0.200741  3.773834e+05\n",
      "16   ì´ìš©ê¸ˆì•¡_ì‹ íŒ_B0M_12         0.188202  6.775198e+02\n",
      "17   ì´ìš©ê±´ìˆ˜_ì‹ íŒ_B0M_11         0.176811  4.332760e+05\n",
      "18    _1ìˆœìœ„ì¹´ë“œì´ìš©ê±´ìˆ˜_12         0.152232  2.542653e+02\n",
      "19   ì´ìš©ê¸ˆì•¡_í• ë¶€_B0M_07         0.150388  1.103214e+01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# 1. SHAP Value ê³„ì‚° (ì „ì²´ í”¼ì²˜ ëŒ€ìƒ)\n",
    "# ëª¨ë¸ì´ ì–´ë–¤ ë³€ìˆ˜ì— ë°˜ì‘í–ˆëŠ”ì§€ ì „ìˆ˜ ì¡°ì‚¬ë¥¼ ì‹œì‘í• ê²Œ!\n",
    "explainer = shap.TreeExplainer(model_full)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# ë³€ìˆ˜ë³„ í‰ê·  ì ˆëŒ€ SHAP ê°’ì„ ê³„ì‚°í•´ì„œ ì¤‘ìš”ë„ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸°\n",
    "shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'SHAP_Importance': shap_importance\n",
    "}).sort_values(by='SHAP_Importance', ascending=False)\n",
    "\n",
    "# 2. ìƒìœ„ ì¤‘ìš” ë³€ìˆ˜ë“¤ì— ëŒ€í•œ VIF ê³„ì‚°\n",
    "# í”¼ì²˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ VIF ê³„ì‚°ì´ ë©ˆì¶œ ìˆ˜ ìˆì–´. \n",
    "# ìš°ì„  ê°€ì¥ ì¤‘ìš”í•œ ìƒìœ„ 50ê°œ í”¼ì²˜ë¥¼ ê³¨ë¼ì„œ VIFë¥¼ ì¸¡ì •í•´ì¤„ê²Œ!\n",
    "top_n = 50\n",
    "top_features = importance_df.head(top_n)['Feature'].tolist()\n",
    "X_vif_target = X[top_features]\n",
    "\n",
    "print(f\"ìƒë¦¼ì•„! ìƒìœ„ {top_n}ê°œ í•µì‹¬ í”¼ì²˜ì˜ VIF ì§€ìˆ˜ë¥¼ ê³„ì‚° ì¤‘ì´ì•¼. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ì¤˜! ğŸŒˆ\")\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = top_features\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif_target.values, i) for i in range(len(top_features))]\n",
    "\n",
    "# 3. SHAPì™€ VIF í•©ì¹˜ê¸°\n",
    "# ë‘ ì •ë³´ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì„œ ìƒë¦¼ì´ê°€ ë³´ê¸° í¸í•˜ê²Œ ì •ë ¬í• ê²Œ!\n",
    "final_analysis = pd.merge(importance_df, vif_data, on='Feature', how='left')\n",
    "\n",
    "# VIFê°€ ê²°ì¸¡ì¹˜ì¸ ê±´ ìƒìœ„ 50ìœ„ ë°–ì˜ ë³€ìˆ˜ë“¤ì´ì•¼!\n",
    "print(final_analysis.head(20))\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥í•´ì„œ ë‚˜ì¤‘ì— ë³´ê³ ì„œì— ë°”ë¡œ ì“°ì!\n",
    "final_analysis.to_csv('VIP_WiderFormat_Shap_Vif.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761e998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
